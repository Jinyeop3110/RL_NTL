- data.train_files=/home/yeopjin/orcd/pool/workspace/RL_NTL/data/train.parquet
- data.val_files=/home/yeopjin/orcd/pool/workspace/RL_NTL/data/test.parquet
- data.train_batch_size=256
- data.val_batch_size=1312
- data.max_prompt_length=1024
- data.max_response_length=512
- actor_rollout_ref.model.path=Qwen/Qwen2.5-0.5B-Instruct
- actor_rollout_ref.model.enable_gradient_checkpointing=false
- actor_rollout_ref.hybrid_engine=true
- actor_rollout_ref.actor.strategy=fsdp
- actor_rollout_ref.actor.ppo_mini_batch_size=64
- actor_rollout_ref.actor.ppo_micro_batch_size=4
- actor_rollout_ref.actor.ppo_epochs=1
- actor_rollout_ref.actor.clip_ratio=0.2
- actor_rollout_ref.actor.entropy_coeff=0.001
- actor_rollout_ref.actor.grad_clip=1.0
- actor_rollout_ref.actor.shuffle=true
- actor_rollout_ref.actor.optim.lr=1e-06
- actor_rollout_ref.actor.optim.lr_warmup_steps_ratio=0.0
- actor_rollout_ref.actor.optim.warmup_style=constant
- actor_rollout_ref.actor.fsdp_config.param_offload=false
- actor_rollout_ref.actor.fsdp_config.optimizer_offload=false
- actor_rollout_ref.ref.fsdp_config.param_offload=true
- actor_rollout_ref.ref.log_prob_micro_batch_size=4
- actor_rollout_ref.rollout.name=vllm
- actor_rollout_ref.rollout.tensor_model_parallel_size=1
- actor_rollout_ref.rollout.dtype=bfloat16
- actor_rollout_ref.rollout.temperature=1.0
- actor_rollout_ref.rollout.top_k=-1
- actor_rollout_ref.rollout.top_p=1
- actor_rollout_ref.rollout.do_sample=true
- actor_rollout_ref.rollout.prompt_length=1024
- actor_rollout_ref.rollout.response_length=512
- actor_rollout_ref.rollout.gpu_memory_utilization=0.4
- actor_rollout_ref.rollout.enforce_eager=true
- actor_rollout_ref.rollout.free_cache_engine=true
- actor_rollout_ref.rollout.ignore_eos=false
- actor_rollout_ref.rollout.load_format=dummy_dtensor
- actor_rollout_ref.rollout.max_num_batched_tokens=8192
- actor_rollout_ref.rollout.max_num_seqs=1024
- actor_rollout_ref.rollout.log_prob_micro_batch_size=4
- critic.model.path=Qwen/Qwen2.5-0.5B-Instruct
- critic.model.enable_gradient_checkpointing=false
- critic.model.fsdp_config.param_offload=false
- critic.model.fsdp_config.optimizer_offload=false
- critic.strategy=fsdp
- critic.ppo_mini_batch_size=64
- critic.ppo_micro_batch_size_per_gpu=1
- critic.ppo_epochs=1
- critic.cliprange_value=0.5
- critic.grad_clip=1.0
- critic.shuffle=true
- critic.optim.lr=1e-05
- critic.optim.lr_warmup_steps_ratio=0.0
- critic.optim.warmup_style=constant
- algorithm.gamma=1.0
- algorithm.lam=1.0
- algorithm.adv_estimator=gae
- algorithm.kl_ctrl.type=fixed
- algorithm.kl_ctrl.kl_coef=0.001
- algorithm.kl_penalty=kl
- reward_model.enable=false
- reward_model.micro_batch_size=64
- reward_model.reward_manager=naive
- custom_reward_function.path=/home/yeopjin/orcd/pool/workspace/RL_NTL/custom_NTL.py
- custom_reward_function.name=compute_score
- trainer.project_name=RL-NTL
- trainer.experiment_name=gsm8k-ppo-qwen2.5-0.5b-Jul29
- trainer.n_gpus_per_node=4
- trainer.nnodes=1
- trainer.total_epochs=15
- trainer.test_freq=10
- trainer.critic_warmup=0
- trainer.save_freq=-1
- trainer.logger=['console', 'wandb']
- +trainer.mode=standard
